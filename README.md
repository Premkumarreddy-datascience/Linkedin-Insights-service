# LinkedIn Insights API

A **production-style FastAPI backend** that scrapes, stores, and analyzes LinkedIn company data such as **company pages, posts, employees, and engagement metrics**.

This project is designed with **clean architecture**, **service-layer abstraction**, **Docker-based deployment**, and **RESTful APIs**.

---

## ğŸš€ Key Features

-  Fetch or scrape LinkedIn company pages
-  Store and retrieve company posts
-  Engagement analytics
-  Employee listing, search, and distribution analysis
-  Auto-refresh outdated data
-  Fully Dockerized (FastAPI + MySQL)
-  Postman collection for API testing
-  Pytest-based backend tests

---

## Tech Stack

The project uses a modern, production-ready technology stack focused on performance, scalability, and maintainability.

| Category | Technology | Purpose |
|--------|-----------|---------|
| Backend Framework | FastAPI | High-performance API framework for building RESTful services |
| Programming Language | Python | Core backend development language |
| ASGI Server | Uvicorn | Runs the FastAPI application |
| ORM | SQLAlchemy | Database ORM for query building and model management |
| Data Validation | Pydantic | Request/response validation and serialization |
| Database | MySQL | Relational database for persistent storage |
| Database Driver | PyMySQL | Pythonâ€“MySQL database connector |
| API Documentation | Swagger UI (OpenAPI) | Interactive API documentation |
| Testing Framework | Pytest | Unit and API testing |
| Async HTTP Client | HTTPX | Used for API testing |
| Environment Management | python-dotenv | Load environment variables securely |
| Migrations | Alembic | Database schema migrations |
| Message Broker (Optional) | Redis | Used with Celery for async tasks |
| Containerization (Optional) | Docker | Application containerization |
| Version Control | Git | Source code version control |
| IDE / Editor | VS Code | Development environment |
| OS | Windows / Linux | Development & deployment environments |


## ğŸ“ Project Structure

```
Linkedin Insights service/
â”œâ”€â”€ app/
â”‚Â  Â â”œâ”€â”€ __init__.py
â”‚Â  Â â”œâ”€â”€ main.py
â”‚Â  Â â”œâ”€â”€ database.py
â”‚Â  Â â”œâ”€â”€ schemas.py
â”‚Â  Â â”œâ”€â”€ models/
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ __init__.py
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ page.py
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ post.py
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ user.py
â”‚Â  Â â”‚Â  Â â””â”€â”€ comment.py
â”‚Â  Â â”œâ”€â”€ services/
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ __init__.py
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ page_service.py
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ post_service.py
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ user_service.py
â”‚Â  Â â”‚Â  Â â””â”€â”€ comment_service.py
â”‚Â  Â â”œâ”€â”€ scrapers/
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ __init__.py
â”‚Â  Â â”‚Â  Â â””â”€â”€ linkedin_scraper.py
â”‚Â  Â â””â”€â”€ api/
â”‚Â  Â  Â  Â â”œâ”€â”€ __init__.py
â”‚Â  Â  Â  Â â”œâ”€â”€ endpoints.py
â”‚Â  Â  Â  Â â””â”€â”€ dependencies.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ Postman Collection.json
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚Â  Â â”œâ”€â”€ test_health.py
â”‚Â  Â â”œâ”€â”€ test_pages.py
â”‚Â  Â â”œâ”€â”€ test_posts.py
â”‚Â  Â â””â”€â”€ test_search.py
â””â”€â”€ README.md
```
##  Quick Start

### 1. Start the Application

```bash
# Clone/Create project folder
git clone <repo-url>   # or create manually
cd Linkedin_Insights_Service_API

# Start all services
docker-compose up -d

# Check status
docker-compose ps
```
### 2. Verify It's Working

```bash
# Test the API
curl http://localhost:8000/

# Should return:
# {"message":"LinkedIn Insights Service API","status":"running"}

# Open API documentation
# Browser: http://localhost:8000/docs
```

### 3. View Logs
```bash
# view all logs
docker=-compose lgs

# Follow web service logs
docker-compose logs -f web

# Check specific service
docker-compose logs db
docker-compose logs redis
```

### Check Database
```bash
# Connect to MySQL
docker-compose exec db mysql -uroot -p linkedin_db

# Common queries
SHOW TABLES;
SELECT * FROM pages LIMIT 5;
```

## Database Seeding (CMD+SQL)
### Open MySQL inside Docker
```bash
docker-compose exec db mysql -u root -p
```
Password
```bash
Enter passwrod
```
USE the database which has been created:
```sql
USE linkedin_db;
```
### Insert Pages
```sql
Insert Records into all tables pages, posts, users, comments
```
### Verify Query
```sql
SELECT COUNT(*) FROM pages;
SELECT page_id, COUNT(*) FROM posts GROUP BY page_id;
SELECT page_id, COUNT(*) FROM social_media_users GROUP BY page_id;
```

## Configuration

### Environment Vaiables
Create .env file:
```bash
#Database
DATABASE_URL=mysql+pymysql://username:password@db:3307/sample_database
REDIS_URL=redis://redis:6379/0
#Scraping
SCRAPE_TIMEOUT=30
MAX_POSTS_PER_PAGE=25
CACHE_TTL=3600
EOF
```

## Access Points

| Service | URL |
| :--- | :--- |
| API | http://localhost:8000 |
| API Docs | http://localhost:8000/docs |
| MySQL | localhost:3307 |
| Redis | localhost:6379 |

## API Endpoints Summary
### Health
```
GET /api/v1/health/db
```

### Pages
```
GET /api/v1/pages/{page_id}

GET /api/v1/pages
```

### Posts
```
GET /api/v1/pages/{page_id}/posts/recent

GET /api/v1/pages/{page_id}/posts/with-comments

GET /api/v1/pages/{page_id}/posts/search

GET /api/v1/pages/{page_id}/top-posts

GET /api/v1/pages/{page_id}/engagement
```

### Employees
```
GET /api/v1/pages/{page_id}/employees

GET /api/v1/pages/{page_id}/employees/search

GET /api/v1/pages/{page_id}/employees/distribution

GET /api/v1/pages/{page_id}/employees/recent
```

## Testing
```bash
docker-compose exec web pytest
```
This will test Database Connection and all Service Layers

## Postman Usage
- Import Postman Collection.JSON file into Postman
- set variables:
```
base_url = http://localhost:8000/api/v1
page_id = google
```
Change page_id to test any company

## Requirements
- Docker & Docker Compose
- Minimum 4 GB RAM
- Ports 8000, 3307, 6379 available




